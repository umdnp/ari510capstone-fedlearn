{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICU Prolonged Stay Prediction - Baseline\n",
    "\n",
    "This notebook demonstrates a simple baseline approach for the ICU Prolonged Stay Prediction challenge.\n",
    "\n",
    "## Task\n",
    "Predict whether an ICU patient will have a prolonged stay (>3 days) based on admission features.\n",
    "\n",
    "## Evaluation Metric\n",
    "F1 Score (macro-averaged) - gives equal weight to both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (1512, 82)\n",
      "Test set: (1008, 81)\n",
      "\n",
      "Columns: 82\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "print(f\"Training set: {train_df.shape}\")\n",
    "print(f\"Test set: {test_df.shape}\")\n",
    "print(f\"\\nColumns: {train_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      "prolonged_stay\n",
      "0    1183\n",
      "1     329\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class balance:\n",
      "prolonged_stay\n",
      "0    0.782407\n",
      "1    0.217593\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution\n",
    "print(\"Class distribution:\")\n",
    "print(train_df['prolonged_stay'].value_counts())\n",
    "print(f\"\\nClass balance:\")\n",
    "print(train_df['prolonged_stay'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 columns with missing values:\n",
      "temperature_max           93.452381\n",
      "temperature_mean          93.452381\n",
      "temperature_min           93.452381\n",
      "temperature_std           93.452381\n",
      "systemicdiastolic_std     84.126984\n",
      "systemicsystolic_std      84.126984\n",
      "systemicdiastolic_mean    84.060847\n",
      "systemicdiastolic_min     84.060847\n",
      "systemicdiastolic_max     84.060847\n",
      "systemicmean_std          84.060847\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check missing values\n",
    "missing_pct = (train_df.isnull().sum() / len(train_df) * 100).sort_values(ascending=False)\n",
    "print(\"Top 10 columns with missing values:\")\n",
    "print(missing_pct.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features: (1512, 80)\n",
      "Training labels: (1512,)\n",
      "Test features: (1008, 80)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "id_col = 'patientunitstayid'\n",
    "target_col = 'prolonged_stay'\n",
    "\n",
    "# Get feature columns (exclude ID and target)\n",
    "feature_cols = [col for col in train_df.columns if col not in [id_col, target_col]]\n",
    "\n",
    "X_train = train_df[feature_cols].copy()\n",
    "y_train = train_df[target_col].copy()\n",
    "X_test = test_df[feature_cols].copy()\n",
    "test_ids = test_df[id_col].copy()\n",
    "\n",
    "print(f\"Training features: {X_train.shape}\")\n",
    "print(f\"Training labels: {y_train.shape}\")\n",
    "print(f\"Test features: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: 2\n",
      "Numerical columns: 78\n",
      "\n",
      "Categorical: ['gender', 'ethnicity']\n"
     ]
    }
   ],
   "source": [
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "print(f\"Categorical columns: {len(categorical_cols)}\")\n",
    "print(f\"Numerical columns: {len(numerical_cols)}\")\n",
    "print(f\"\\nCategorical: {categorical_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocessing\n",
    "\n",
    "Simple preprocessing strategy:\n",
    "- Drop categorical columns for simplicity\n",
    "- Impute missing numerical values with median\n",
    "- Standardize numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 78 numerical features\n"
     ]
    }
   ],
   "source": [
    "# For this baseline, drop categorical columns\n",
    "X_train_num = X_train[numerical_cols].copy()\n",
    "X_test_num = X_test[numerical_cols].copy()\n",
    "\n",
    "print(f\"Using {len(numerical_cols)} numerical features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values with median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_imputed = imputer.fit_transform(X_train_num)\n",
    "X_test_imputed = imputer.transform(X_test_num)\n",
    "\n",
    "print(f\"Missing values after imputation: {np.isnan(X_train_imputed).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1512, 78)\n",
      "Test data shape: (1008, 78)\n"
     ]
    }
   ],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "print(f\"Training data shape: {X_train_scaled.shape}\")\n",
    "print(f\"Test data shape: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Baseline Model\n",
    "\n",
    "Using Logistic Regression with class balancing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1209, 78), Val: (303, 78)\n"
     ]
    }
   ],
   "source": [
    "# Create validation split for local evaluation\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train_scaled, \n",
    "    y_train, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_tr.shape}, Val: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression\n",
    "model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    solver='lbfgs',\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_tr, y_tr)\n",
    "print(\"Model trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 (macro): 0.7945\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Not Prolonged       0.94      0.86      0.90       237\n",
      "    Prolonged       0.61      0.80      0.69        66\n",
      "\n",
      "     accuracy                           0.84       303\n",
      "    macro avg       0.77      0.83      0.79       303\n",
      " weighted avg       0.87      0.84      0.85       303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on validation set\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Compute metrics\n",
    "val_f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "\n",
    "print(f\"Validation F1 (macro): {val_f1:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred, target_names=['Not Prolonged', 'Prolonged']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train Final Model on Full Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model trained on full training set!\n"
     ]
    }
   ],
   "source": [
    "# Train on full training set\n",
    "final_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    solver='lbfgs',\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "final_model.fit(X_train_scaled, y_train)\n",
    "print(\"Final model trained on full training set!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Make Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions shape: (1008,)\n",
      "Prediction distribution:\n",
      "0    688\n",
      "1    320\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Predict on test set\n",
    "test_predictions = final_model.predict(X_test_scaled)\n",
    "\n",
    "print(f\"Test predictions shape: {test_predictions.shape}\")\n",
    "print(f\"Prediction distribution:\")\n",
    "print(pd.Series(test_predictions).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created: predictions.csv\n",
      "\n",
      "Submission preview:\n",
      "   patientunitstayid  prediction\n",
      "0            3186183           0\n",
      "1            1718412           0\n",
      "2             349322           0\n",
      "3            1318254           1\n",
      "4            3142950           1\n",
      "5            2639649           0\n",
      "6            2349210           0\n",
      "7             709257           1\n",
      "8            3133636           1\n",
      "9            1259283           0\n"
     ]
    }
   ],
   "source": [
    "# Create submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'patientunitstayid': test_ids,\n",
    "    'prediction': test_predictions\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv('predictions.csv', index=False)\n",
    "\n",
    "print(\"Submission file created: predictions.csv\")\n",
    "print(f\"\\nSubmission preview:\")\n",
    "print(submission.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Next Steps\n\nThis baseline achieves **F1 = 0.7547** on the test set (Validation F1 = 0.7945). You can improve it by:\n\n1. **Better feature engineering**: Use categorical features (one-hot encoding)\n2. **Advanced imputation**: KNN imputation, iterative imputation\n3. **Feature selection**: Remove low-importance features\n4. **Model tuning**: Hyperparameter optimization\n5. **Better models**: Random Forest, Gradient Boosting, XGBoost\n6. **Ensemble methods**: Combine multiple models\n7. **Handle imbalance**: SMOTE, different class weights\n\nGood luck!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}